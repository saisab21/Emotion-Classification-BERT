{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saisa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Version: 2.5.1+cpu\n",
      "Transformers Version: 4.46.2\n",
      "Pandas Version: 2.2.3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import pandas as pd\n",
    "print(\"Torch Version:\", torch.__version__)\n",
    "print(\"Transformers Version:\", transformers.__version__)\n",
    "print(\"Pandas Version:\", pd.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  141k  100  141k    0     0   207k      0 --:--:-- --:--:-- --:--:--  208k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  3 35259    3  1378    0     0   3752      0  0:00:09 --:--:--  0:00:09  3817\n",
      "100 35259  100 35259    0     0  91928      0 --:--:-- --:--:-- --:--:-- 93277\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Joy</th>\n",
       "      <th>Fear</th>\n",
       "      <th>Anger</th>\n",
       "      <th>Sadness</th>\n",
       "      <th>Surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The light would come all the way up to your ve...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well, my birthday is in January.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tears in my eyes, too much on my mind, and dee...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My eyes scanned quickly into every room, every...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I felt the afterglow of the late afternoon sun...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  Joy  Fear  Anger  \\\n",
       "0  The light would come all the way up to your ve...    0     1      0   \n",
       "1                   Well, my birthday is in January.    0     0      0   \n",
       "2  Tears in my eyes, too much on my mind, and dee...    0     1      0   \n",
       "3  My eyes scanned quickly into every room, every...    0     1      1   \n",
       "4  I felt the afterglow of the late afternoon sun...    1     0      0   \n",
       "\n",
       "   Sadness  Surprise  \n",
       "0        0         1  \n",
       "1        0         0  \n",
       "2        1         0  \n",
       "3        0         0  \n",
       "4        0         0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use curl to download the dataset files\n",
    "!curl -O https://raw.githubusercontent.com/debajyotimaz/nlp_assignment/main/train_split.csv\n",
    "!curl -O https://raw.githubusercontent.com/debajyotimaz/nlp_assignment/main/test_split.csv\n",
    "\n",
    "# Load the training data\n",
    "import pandas as pd\n",
    "train_data = pd.read_csv(\"train_split.csv\")\n",
    "train_data.head()  # Display the first few rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saisa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\saisa\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer and model are initialized.\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary components from transformers\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# Initialize the BERT tokenizer and model\n",
    "# Setting up 5 labels for multi-label classification (Joy, Fear, Anger, Sadness, Surprise)\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=5)\n",
    "\n",
    "print(\"Tokenizer and model are initialized.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of Data for Training (Tokenization and Batch Preparation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing complete. Dataloader is ready.\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# # Function to preprocess text data and labels\n",
    "# def preprocess_data(data, tokenizer, max_length=128):\n",
    "#     # Tokenize text and create input IDs and attention masks\n",
    "#     texts = data[\"text\"].tolist()\n",
    "#     labels = data[[\"Joy\", \"Fear\", \"Anger\", \"Sadness\", \"Surprise\"]].values\n",
    "\n",
    "#     input_ids, attention_masks = [], []\n",
    "#     for text in texts:\n",
    "#         encoded = tokenizer.encode_plus(\n",
    "#             text, \n",
    "#             add_special_tokens=True, \n",
    "#             max_length=max_length,\n",
    "#             padding='max_length', \n",
    "#             truncation=True, \n",
    "#             return_attention_mask=True, \n",
    "#             return_tensors='pt'\n",
    "#         )\n",
    "#         input_ids.append(encoded['input_ids'])\n",
    "#         attention_masks.append(encoded['attention_mask'])\n",
    "\n",
    "#     # Convert lists to tensors\n",
    "#     input_ids = torch.cat(input_ids, dim=0)\n",
    "#     attention_masks = torch.cat(attention_masks, dim=0)\n",
    "#     labels = torch.tensor(labels, dtype=torch.float)\n",
    "\n",
    "#     # Create DataLoader for batch processing\n",
    "#     batch_size = 8\n",
    "#     dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "#     dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "#     return dataloader\n",
    "\n",
    "# # Preprocess the training data\n",
    "# train_dataloader = preprocess_data(train_data, tokenizer)\n",
    "# print(\"Data preprocessing complete. Dataloader is ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Average Loss: 0.5556147690117359\n",
      "Epoch 2/3, Average Loss: 0.4160565833747387\n",
      "Epoch 3/3, Average Loss: 0.3180561403930187\n"
     ]
    }
   ],
   "source": [
    "# from torch.optim import AdamW\n",
    "\n",
    "# # Define the training function\n",
    "# def train_model(model, dataloader, epochs=3, lr=1e-5):\n",
    "#     # Set up the optimizer\n",
    "#     optimizer = AdamW(model.parameters(), lr=lr)\n",
    "#     model.train()  # Put the model in training mode\n",
    "    \n",
    "#     # Training loop\n",
    "#     for epoch in range(epochs):\n",
    "#         total_loss = 0  # Track the loss for each epoch\n",
    "#         for batch in dataloader:\n",
    "#             # Unpack the batch and send to GPU if available\n",
    "#             b_input_ids, b_attention_masks, b_labels = batch\n",
    "\n",
    "#             # Clear previous gradients\n",
    "#             optimizer.zero_grad()\n",
    "\n",
    "#             # Forward pass: calculate the loss\n",
    "#             outputs = model(input_ids=b_input_ids, attention_mask=b_attention_masks, labels=b_labels)\n",
    "#             loss = outputs.loss\n",
    "\n",
    "#             # Backward pass: calculate gradients\n",
    "#             loss.backward()\n",
    "\n",
    "#             # Update weights\n",
    "#             optimizer.step()\n",
    "\n",
    "#             # Accumulate the loss\n",
    "#             total_loss += loss.item()\n",
    "        \n",
    "#         # Calculate average loss for the epoch\n",
    "#         avg_loss = total_loss / len(dataloader)\n",
    "#         print(f\"Epoch {epoch + 1}/{epochs}, Average Loss: {avg_loss}\")\n",
    "\n",
    "# # Train the model\n",
    "# train_model(model, train_dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Trained Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved to 'emotion_classification_model' directory.\n"
     ]
    }
   ],
   "source": [
    "# Save the model and tokenizer to a directory for future use\n",
    "model.save_pretrained(\"emotion_classification_model\")\n",
    "tokenizer.save_pretrained(\"emotion_classification_model\")\n",
    "\n",
    "print(\"Model and tokenizer saved to 'emotion_classification_model' directory.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining an Inference Function to Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted emotions: {'Joy': True, 'Fear': False, 'Anger': False, 'Sadness': False, 'Surprise': False}\n"
     ]
    }
   ],
   "source": [
    "# Function to predict emotions in a text sample\n",
    "def predict_emotions(text, model, tokenizer):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "    \n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Run inference without calculating gradients\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Get the logits (raw model outputs)\n",
    "    logits = outputs.logits\n",
    "    # Apply sigmoid to get probabilities and threshold at 0.5 to convert to binary labels\n",
    "    predicted_emotions = (logits.sigmoid() > 0.5).int().tolist()[0]\n",
    "    \n",
    "    # Define emotion labels\n",
    "    emotion_labels = [\"Joy\", \"Fear\", \"Anger\", \"Sadness\", \"Surprise\"]\n",
    "    \n",
    "    # Create a dictionary to map emotion labels to their predictions\n",
    "    return {emotion: bool(pred) for emotion, pred in zip(emotion_labels, predicted_emotions)}\n",
    "\n",
    "# Example test for the function with a sample text\n",
    "sample_text = \"I'm feeling absolutely thrilled and joyous today!\"\n",
    "print(\"Predicted emotions:\", predict_emotions(sample_text, model, tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
